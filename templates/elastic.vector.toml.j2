[sources.kafka_logging_syslog_raw]
  # pulls the syslog events from the kafka topic

  type = "kafka"
  bootstrap_servers = "{{ hpviz_broker_bootstrap_server1 }}:{{ hpviz_broker_bootstrap_port1 }}" # IP required not hostname
  key_field = "host"
  topics = ["logging.syslog.raw"]
  group_id= "elasticsearch-ingestion"

[sources.kafka_logging_syslog_processed]
  # pulls the syslog events from the kafka topic

  type = "kafka"
  bootstrap_servers = "{{ hpviz_broker_bootstrap_server1 }}:{{ hpviz_broker_bootstrap_port1 }}" # IP required not hostname
  key_field = "host"
  topics = ["logging.syslog.processed"]
  group_id= "elasticsearch-ingestion"

[transforms.kafka_message]
  #
  # this process processes the kafka 'message' field which is in json format and is the full syslog event
  # pushed to kafka topic, once processed it deletes the original 'message' field
  # this is required otherwise elastic will just index the message field as a string
  #
  type="json_parser"
  # inputs = ["kafka_logging_syslog_raw", "kafka_logging_syslog_processed"]
  inputs = ["kafka_logging_syslog_processed"]
  field = "message"
  drop_field = true
  drop_invalid = false
  overwrite_target = true


[sinks.elasticsearch_syslog]
  # 
  # Currently only 'processed' logs are ingested
  #  'raw are left on raw topic'
  #  pushes the JSON syslog event to elastic for indexing
  #
  
  type = "elasticsearch"
  inputs = ["kafka_message"]
  compression = "none"
  doc_type = "_doc"
  healthcheck = true
  host = "http://elasticsearch:9200"
  index = "syslog-%Y.%m.%d"

  batch.max_bytes = 10490000
  batch.max_events = 1000
  batch.timeout_secs = 1

  headers.X-Powered-By = "Vector"
