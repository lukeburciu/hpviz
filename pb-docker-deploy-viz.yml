---
##################
## pb-docker-deploy.yml
##
## This playbook manages and deploys docker services on the remote server using
##  the docker-compose files located in the '/var/opt/hpviz/docker' directory
##    docker-compose.override.yml is merged for production overrides
##
##  Remote Requirements:
##    - docker container service running
##    - docker-compose installed
##
- name: Deploy Docker Containers
  hosts: viz
  gather_facts: no
  become: True

  tasks:

    - name: Check required variables exists for docker to install
      assert:
        that:
          - hpviz_base_dir is defined
          - hpviz_base_dir | length > 0
          - hpviz_vector_hostkey is defined
          - hpviz_vector_hostkey | length > 0
          - hpviz_virtual_hostname is defined
          - hpviz_virtual_hostname | length > 0
          - hpviz_syslog_ingest_ip is defined
          - hpviz_syslog_ingest_ip | length > 0
          - hpviz_syslog_ingest_port is defined
          - hpviz_syslog_ingest_port | length > 0
      tags:
        - structure

    - name: add project groups
      group:
        name: "{{ item }}"
        state: present
        system: yes
      loop:
        - hpviz
        - www-data
      tags:
        - accounts

    - name: Add system accounts
      user:
        name: "{{ item }}"
        comment: HPViz system account
        system: yes
        groups: hpviz
        state: present
      loop:
        - kafka
        - kafka-connect
        - zookeeper
        - grafana
        - elastic
        - vector
        - neo4j
        - nifi
        - www-data
        - grafana
      tags:
        - accounts

    - name: Check project top level directory exist "{{ hpviz_base_dir }}"
      file:
        path: "{{ hpviz_base_dir }}"
        state: directory
        group: hpviz
        mode: 2775
        # files: -rwxrwsr-x; folders: drwxrwsr-x
      tags:
       - structure
       - skip_ansible_lint  # 206 error

    # - name: Set project directory group inheritance
    #   file:
    #     path: "{{ hpviz_base_dir }}"
    #     state: directory
    #     mode: 'g+s'
    #   tags:
    #    - structure

    - name: Set up project directories
      file:
        path: "{{ item.0 }}"
        owner: root
        state: directory
        group: hpviz
        mode: 2775
        # files: -rwxrwsr-x; folders: drwxrwsr-x
      loop:
        # docker compose home
        - ["{{ hpviz_base_dir }}/docker", 'root']
        # configs
        - ["{{ hpviz_base_dir }}/etc", 'root']
        - ["{{ hpviz_base_dir }}/etc/ssl/ca-certificates", 'root']
        - ["{{ hpviz_base_dir }}/etc/neo4j", 'neo4j']
        - ["{{ hpviz_base_dir }}/etc/neo4j/certs", 'neo4j']
        - ["{{ hpviz_base_dir }}/etc/neo4j/plugins", 'neo4j']
        - ["{{ hpviz_base_dir }}/etc/elastic/certs", 'elastic']
        - ["{{ hpviz_base_dir }}/etc/nginx/certs", 'root']     # **TODO Check if correct user
        - ["{{ hpviz_base_dir }}/etc/kafka/secrets", 'kafka']
        - ["{{ hpviz_base_dir }}/etc/kafka-connect/plugins", 'kafka-connect']
        - ["{{ hpviz_base_dir }}/etc/vector-ingest/certs",'vector']
        - ["{{ hpviz_base_dir }}/etc/vector2elastic/certs",'vector']
        - ["{{ hpviz_base_dir }}/etc/nifi/certs", 'nifi']
        - ["{{ hpviz_base_dir }}/etc/grafana/certs", 'grafana']
        - ["{{ hpviz_base_dir }}/etc/grafana/plugins", 'grafana']
        - ["{{ hpviz_base_dir }}/etc/grafana/datasources", 'grafana']
        - ["{{ hpviz_base_dir }}/etc/grafana/dashboards", 'grafana']
        # data
        - ["{{ hpviz_base_dir }}/data", 'root']
        - ["{{ hpviz_base_dir }}/data/zookeeper", 'zookeeper']
        - ["{{ hpviz_base_dir }}/data/elastic", 'elastic']
        - ["{{ hpviz_base_dir }}/data/kafka",'kafka']
        - ["{{ hpviz_base_dir }}/data/nifi",'nifi']
        - ["{{ hpviz_base_dir }}/data/vector-ingest",'vector']
        - ["{{ hpviz_base_dir }}/data/vector2elastic",'vector']
        - ["{{ hpviz_base_dir }}/data/neo4j", 'neo4j']
        - ["{{ hpviz_base_dir }}/data/neo4j/data", 'neo4j']
        - ["{{ hpviz_base_dir }}/data/neo4j/metrics", 'neo4j']
        - ["{{ hpviz_base_dir }}/data/grafana", 'root']
        # logs
        - ["{{ hpviz_base_dir }}/logs", 'root']
        - ["{{ hpviz_base_dir }}/logs/elastic", 'elastic']
        - ["{{ hpviz_base_dir }}/logs/neo4j", 'neo4j']
        - ["{{ hpviz_base_dir }}/logs/zookeeper", 'zookeeper']
        - ["{{ hpviz_base_dir }}/logs/kafka", 'kafka']
        - ["{{ hpviz_base_dir }}/logs/vector-ingest", 'vector']
        - ["{{ hpviz_base_dir }}/logs/vector2elastic", 'vector']
        - ["{{ hpviz_base_dir }}/logs/nifi", 'nifi']
      tags:
        - structure
        - skip_ansible_lint

    - name: Check ingestion vector on viz hosts TOML config exists
      template:
        src: templates/viz.vector.toml.j2
        dest: "{{ hpviz_base_dir }}/etc/vector-ingest/viz.vector.toml"
        mode: 0640
      tags:
        - vector-ingest
        - configs
        - containers

    - name: Check vector 2 elastic TOML config exists
      template:
        src: templates/elastic.vector.toml.j2
        dest: "{{ hpviz_base_dir }}/etc/vector2elastic/elastic.vector.toml"
        mode: 0640
      tags:
        - vector2elastic
        - configs
        - containers

    - name: Check rsyslog config exist
      template:
        src: templates/rsyslog.conf.j2
        dest: "/etc/rsyslog.d/99-hpviz-ingest.conf"
        mode: 0644
      tags:
        - vector
        - configs
        - containers

    - name: restart rsyslog
      service:
        name: rsyslog
        state: restarted
      tags:
        - vector
        - configs
        - containers

    - name: Define VIZ network (docker)
      docker_network:
        name: viz-net
        state: present
        force: no
        scope: local
        internal: no
        ipam_config:
          - subnet: 172.20.0.0/24
        #driver_options:
          #com.docker.network.bridge.default_bridge: "true"
          #com.docker.network.bridge.enable_ip_masquerade: "true"
          #com.docker.network.bridge.host_binding_ipv4: 0.0.0.0
          #com.docker.network.bridge.enable_icc: "true"
      tags:
        - network
        - containers

    # - name: stopping Zookeeper container
    #   docker_container:
    #     name: zookeeper
    #     image: confluentinc/cp-zookeeper
    #     state: absent
    #   ignore_errors: yes
    #   tags:
    #     - zookeeper
    #     - containers

    - name: Deploy Zookeeper container
      docker_container:
        name: zookeeper
        image: confluentinc/cp-zookeeper
        hostname: zookeeper
        restart: yes
        recreate: yes
        restart_policy: unless-stopped
        state: started
        # ports:
        #   - "2181"
        expose:
          - "2181"
        purge_networks: yes
        networks:
          - name: viz-net
        env:
          ZOOKEEPER_CLIENT_PORT: "2181"
          ZOOKEEPER_TICK_TIME: "2000"
        volumes:
          - "{{ hpviz_base_dir }}/data/zookeeper:/var/lib/zookeeper/data"
          - "{{ hpviz_base_dir }}/logs/zookeeper:/var/lib/zookeeper/log"
          - /var/run/docker.sock:/var/run/docker.sock:ro
      tags:
        - zookeeper
        - containers

    # fixes single node issues when docker has been restarted i.e. after a reboot.  The broker will receive correct clusterid from zookeeper
    - name: removes /opt/hpviz/data/kafka/meta.properties
      file:
        path: /opt/hpviz/data/kafka/meta.properties
        state: absent
      tags:
        - broker
        - containers

    # - name: Stopping Kafka Broker
    #   docker_container:
    #     name: broker
    #     image: confluentinc/cp-server:5.5.1
    #     state: absent
    #   ignore_errors: yes
    #   tags:
    #     - containers
    #     - broker

    - name: Deploy Kafka Broker
      docker_container:
        name: broker
        image: confluentinc/cp-server:5.5.1
        hostname: broker
        restart: yes
        recreate: yes
        restart_policy: unless-stopped
        state: started
        links:
          - zookeeper:zookeeper
        published_ports:
          - "127.0.0.1:9092:9092"
          #- "9093:9093"
        expose:
          - "29092"
        purge_networks: yes
        networks:
          - name: viz-net
            ipv4_address: "172.20.0.10"
            links:
              - zookeeper:zookeeper
        env:
          KAFKA_BROKER_ID: "1"
          KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "LISTENER_INTERNAL:PLAINTEXT,LISTENER_LOCALHOST:PLAINTEXT,LISTENER_EXT:PLAINTEXT"
          KAFKA_ADVERTISED_LISTENERS: "LISTENER_INTERNAL://broker:29092,LISTENER_LOCALHOST://localhost:9092,LISTENER_EXT://viz001.ecu-sri.net:9093"
          KAFKA_LISTENERS: "LISTENER_INTERNAL://:29092,LISTENER_LOCALHOST://0.0.0.0:9092,LISTENER_EXT://0.0.0.0:9093"
          KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
          KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: "1"
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
          KAFKA_JMX_PORT: "9101"
          KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
         # KAFKA_CREATE_TOPICS: "logging.syslog.vector"
          CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "broker:29092"
          CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: "zookeeper:2181"
          CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: "1"
          CONFLUENT_METRICS_ENABLE: 'true'
          CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
          KAFKA_INTER_BROKER_LISTENER_NAME: "LISTENER_INTERNAL"
        volumes:
           - "{{ hpviz_base_dir }}/data/kafka:/var/lib/kafka/data"
           - /var/run/docker.sock:/var/run/docker.sock:ro
      tags:
        - broker
        - containers

    # - name: stopping NIFI container
    #   docker_container:
    #     name: nifi
    #     image: apache/nifi:latest
    #     state: stopped
    #   ignore_errors: yes
    #   tags:
    #     - containers
    #     - nifi

    - name: Deploy NIFI container
      docker_container:
        name: nifi
        image: apache/nifi:latest
        restart: yes
        recreate: yes
        restart_policy: unless-stopped
        state: absent
        ports:
          - "9090:8080"
         # - "127.0.0.1:514:514"
        expose:
          - "9090"
        purge_networks: yes
        links:
          - zookeeper:zookeeper
          - broker:broker
        networks:
          - name: viz-net
            links:
              - zookeeper:zookeeper
              - broker:broker
        env:
          VIRTUAL_HOST: "viz001.ecu-sri.net"
          LETSENCRYPT_HOST: "viz001.ecu-sri.net"
          VIRTUAL_PROTO: "http"
          VIRTUAL_PORT: "9090"
        volumes:
          - /var/run/docker.sock:/var/run/docker.sock:ro
      tags:
        - nifi
        - containers

    # - name: stopping elasticsearch container
    #   docker_container:
    #     name: elasticsearch
    #     image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.0.1
    #     state: stopped
    #   ignore_errors: yes
    #   tags:
    #     - containers
    #     - elastic

    - name: elasticsearch container
      docker_container:
        name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.0.1
        hostname: elasticsearch
        restart: yes
        recreate: yes
        state: started
        restart_policy: unless-stopped
        expose:
          - "9200"
          - "29300"
        ports:
          - "127.0.0.1:9300:9300"
          - "127.0.0.1:9200:9200"
        purge_networks: yes
        networks:
          - name: viz-net
        env:
          discovery.type: single-node
          http.port: '9200'
          ELASTIC_PASSWORD: '{{ hpviz_elastic_password }}'
          http.cors.enabled: "true"
          http.cors.allow-origin: "http://localhost:1358,http://127.0.0.1:1358"
          http.cors.allow-headers: "X-Requested-With,X-Auth-Token,Content-Type,Content-Length,Authorization"
          http.cors.allow-credentials: "true"
          bootstrap.memory_lock: "true"
          ES_JAVA_OPTS: "-Xms2048m -Xmx2048m"
        volumes:
          - "{{ hpviz_base_dir }}/data/elastic:/usr/share/elasticsearch/data"
          - /var/run/docker.sock:/var/run/docker.sock:ro
      tags:
        - elastic
        - containers

    # - name: Removes old Vector container
    #   docker_container:
    #     name: vector
    #     image: timberio/vector:latest-alpine
    #     state: absent

    # - name: stopping vector-ingest container
    #   docker_container:
    #     name: vector-ingest
    #     image: timberio/vector:latest-alpine
    #     state: stopped
    #   ignore_errors: yes
    #   tags:
    #     - containers
    #     - vector-ingest

    - name: Deploy vector-ingestion container
      docker_container:
        name: vector-ingest
        image: timberio/vector:latest-alpine
        restart: yes
        restart_policy: unless-stopped
        state: started
        recreate: yes
        ports:
          - "{{ hpviz_vector_to_vector_ingest_port }}:{{ hpviz_vector_to_vector_ingest_port }}"  # incoming tcp vector link from the sink
          - "{{ hpviz_syslog_ingest_ip }}:{{ hpviz_syslog_ingest_port }}:{{ hpviz_syslog_ingest_port }}"
        purge_networks: yes
        networks:
          - name: viz-net
            links:
              - broker:broker
        expose:
          - "{{ hpviz_syslog_ingest_port }}/udp"
        #  - "9090"
        volumes:
          - "{{ local_ca_file }}:{{ local_ca_file }}"
          - "/etc/ssl/certs/{{ hpviz_vector_hostkey }}.crt:/etc/ssl/certs/{{ hpviz_vector_hostkey }}.crt"
          - "/etc/ssl/private/{{ hpviz_vector_hostkey }}.key:/etc/ssl/private/{{ hpviz_vector_hostkey }}.key"
          - "{{ hpviz_base_dir }}/etc/vector-ingest/viz.vector.toml:/etc/vector/vector.toml:ro"
          - /var/run/docker.sock:/var/run/docker.sock:ro
      tags:
        - vector-ingest
        - containers
        - vector

    # - name: stopping vector2elastic container
    #   docker_container:
    #     name: vector2elastic
    #     image: timberio/vector:latest-alpine
    #     state: stopped
    #   ignore_errors: yes
    #   tags:
    #     - containers
    #     - vector2elastic

    - name: Deploy vector-2-elastic container
      docker_container:
        name: vector2elastic
        image: timberio/vector:latest-alpine
        restart: yes
        restart_policy: unless-stopped
        state: started
        recreate: yes
        purge_networks: yes
        links:
          - broker:broker
          - elasticsearch:elasticsearch
        networks:
          - name: viz-net
            links:
              - broker:broker
              - elasticsearch:elasticsearch
        volumes:
          - "{{ hpviz_base_dir }}/etc/vector2elastic/elastic.vector.toml:/etc/vector/vector.toml:ro"
          - /var/run/docker.sock:/var/run/docker.sock:ro
      tags:
        - vector2elastic
        - containers
        - vector

    # - name: stopping grafana containaer
    #   docker_container:
    #     name: grafana
    #     image: grafana/grafana:latest-ubuntu
    #     state: stopped
    #   ignore_errors: yes
    #   tags:
    #     - containers
    #     - grafana

    - name: Deploy grafana container
      docker_container:
        name: grafana
        image: grafana/grafana:latest-ubuntu
        ports:
          - "127.0.0.1:3000:3000"
        restart: yes
        restart_policy: unless-stopped
        state: started
        recreate: yes
        purge_networks: yes
        links:
          - elasticsearch:elasticsearch
        networks:
          - name: viz-net
            links:
              - elasticsearch:elasticsearch
        volumes:
          #- "{{ hpviz_base_dir }}/etc/grafana/dashboards:/var/lib/grafana/dashboards"
          - "{{ hpviz_base_dir }}/etc/grafana/datasources:/etc/grafana/datasources"
          #- "{{ hpviz_base_dir }}/etc/grafana/plugins:/var/lib/grafana/plugins"
          - "{{ hpviz_base_dir }}/data/grafana:/var/lib/grafana/"
          - /var/run/docker.sock:/tmp/docker.sock:ro
        env:
          GF_SECURITY_ADMIN_PASSWORD: "{{ hpviz_grafana_admin_pass }}"
          GF_INSTALL_PLUGINS: "grafana-clock-panel, \
                                neocat-cal-heatmap-panel, \
                                petrslavotinek-carpetplot-panel,\
                                grafana-polystat-panel,\
                                scadavis-synoptic-panel,\
                                farski-blendstat-panel"
          GF_ALLOW_USERS_SIGN_UP: "false"
          GF_SERVER_PROTOCOL: "http"
          GF_SERVER_PORT: "3000"
          GF_SERVER_DOMAIN: "{{ hpviz_virtual_hostname }}"
          GF_SERVER_ROOT_URL: "https://{{ hpviz_virtual_hostname }}/grafana/"
          GF_SERVER_SERVER_FROM_SUB_PATH: "true"
      tags:
        - containers
        - grafana
